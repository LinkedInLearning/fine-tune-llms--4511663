{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa8cd98",
   "metadata": {},
   "source": [
    "# 05_02_Iterate a fine-tuned model\n",
    "# Customer Support Automation\n",
    "## Automating responses to customer inquiries on various platforms (email, chatbots, social media).\n",
    "### Collect a dataset of customer inquiries and manually crafted responses. This dataset should cover a wide range of common questions, complaints, and feedback, along with the company's standard responses. Ensure to anonymize personal information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606f61f",
   "metadata": {},
   "source": [
    "## Full Project Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126d991",
   "metadata": {},
   "source": [
    "### Install the necesarry libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc699e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai[datalib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1615b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install urllib3==1.26.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26816d3-cef3-4c39-a901-cd7a49d3fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48e61b",
   "metadata": {},
   "source": [
    "### Import the libraries and enviornment file to gain access to the Open API Key\n",
    "#### The key can be generated here: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70841de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5387008",
   "metadata": {},
   "source": [
    "### Authenticate to the API using the API Key\n",
    "#### Pull from environment variables or use openai.api_key = (\"your_key_here\") to hardcode the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf566e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY']  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9e854-9d65-46b9-b08d-7112da95889f",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a93f9b-ca7e-4a2b-9247-03d2145f1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "#input_file=formatted_custom_support.json ; output_file=output.jsonl\n",
    "def json_to_jsonl(input_file, output_file):\n",
    "    \n",
    "    # Open JSON file\n",
    "    f = open(input_file)\n",
    "     \n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "    \n",
    "    # produce JSONL from JSON\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "def check_file_format(dataset):\n",
    "    # Format error checks\n",
    "    format_errors = defaultdict(int)\n",
    "    \n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "            \n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "            \n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "            \n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "                \n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            \n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "        \n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "    \n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No errors found\")\n",
    "\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5568135-24bf-4c5d-83ee-47e20d15113f",
   "metadata": {},
   "source": [
    "### Convert JSON to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78fa9d7-908a-42eb-81eb-69d10d65b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_jsonl('custom_support.json', 'output.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05754c20-deb7-4e3f-8e57-e9907dd6f132",
   "metadata": {},
   "source": [
    "### Check File Format\n",
    "\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16904d3c-0b0f-457b-a3ad-0fcb908f5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 101\n",
      "First example:\n",
      "{'role': 'system', 'content': \"This is a customer support chatbot designed to help with common inquiries for Kesha's Boutique.\"}\n",
      "{'role': 'user', 'content': 'How can I reset my password?'}\n",
      "{'role': 'assistant', 'content': \"You can reset your password by clicking on the 'Forgot Password' link on the login page and following the instructions sent to your email.\"}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"output.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a89f4e-b528-4b4e-b687-8458777224af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format validation\n",
    "check_file_format(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9836ae0-1c33-4ba0-8a88-03fda5ea0c5a",
   "metadata": {},
   "source": [
    "### Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3dc2da-9a08-4fbc-96a7-28ab292e513b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~7049 tokens that will be charged for during training\n",
      "By default, you'll train for 2 epochs on this dataset\n",
      "By default, you'll be charged for ~14098 tokens\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the conversation\n",
    "conversation_length = []\n",
    "\n",
    "for msg in dataset:\n",
    "    messages = msg[\"messages\"]\n",
    "    conversation_length.append(num_tokens_from_messages(messages))\n",
    "    \n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "TARGET_EPOCHS = 2\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in conversation_length)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "\n",
    "num_tokens = n_epochs * n_billing_tokens_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c234a-e9e0-40ee-a7f7-5e03bb768b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11278400000000001\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5-turbo\t$0.0080 / 1K tokens\n",
    "cost = (num_tokens/1000) * 0.0080 \n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd157b0f-dfaa-42a9-a4e5-11ba884efaf3",
   "metadata": {},
   "source": [
    "### Upload File \n",
    "#### Once you have the data validated, the file needs to be uploaded using the \n",
    "#### Files API in order to be used with a fine-tuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c62c42-90a2-480e-b55d-8c58f26dfa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-4wKelNCveEWUzwYJxxx1FpFj', bytes=39681, created_at=1708959985, filename='output.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"output.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd054dc",
   "metadata": {},
   "source": [
    "### Create fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21da05e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-SbkziY4IaWzhF8McTXuARdIv', created_at=1708959999, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-RZLvEijW4GW0KmC3rLIAjZlu', result_files=[], status='validating_files', trained_tokens=None, training_file='file-4wKelNCveEWUzwYJxxx1FpFj', validation_file=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the fine-tuning job \n",
    "# After you've started a fine-tuning job, it may take some time to complete. Your job may be queued \n",
    "# behind other jobs and training a model can take minutes or hours depending on the \n",
    "# model and dataset size. \n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-4wKelNCveEWUzwYJxxx1FpFj\", \n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ebec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-SbkziY4IaWzhF8McTXuARdIv', created_at=1708959999, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0613:keysoft::8wX1foz7', finished_at=1708960666, hyperparameters=Hyperparameters(n_epochs=2, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-RZLvEijW4GW0KmC3rLIAjZlu', result_files=['file-vJCY7Ft7qA2WlYXUSXZwZgdt'], status='succeeded', trained_tokens=13694, training_file='file-4wKelNCveEWUzwYJxxx1FpFj', validation_file=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve job status\n",
    "job_id = \"ftjob-SbkziY4IaWzhF8McTXuARdIv\"\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "# Status field can contain: running or succeeded or failed, etc.\n",
    "client.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd98e42-8dac-438b-a622-4f361d0434f1",
   "metadata": {},
   "source": [
    "### Evaluate results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd35ca4d-3a41-42d8-baad-1ee0e219158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_mean_token_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.90440</td>\n",
       "      <td>0.70968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.16883</td>\n",
       "      <td>0.79167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.79802</td>\n",
       "      <td>0.36667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.33116</td>\n",
       "      <td>0.63889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.82648</td>\n",
       "      <td>0.60714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>0.56186</td>\n",
       "      <td>0.75676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>0.51107</td>\n",
       "      <td>0.80645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>0.43155</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>0.61842</td>\n",
       "      <td>0.80952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0.66698</td>\n",
       "      <td>0.82609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
       "0       1     1.90440         0.70968         NaN                        NaN\n",
       "1       2     1.16883         0.79167         NaN                        NaN\n",
       "2       3     2.79802         0.36667         NaN                        NaN\n",
       "3       4     1.33116         0.63889         NaN                        NaN\n",
       "4       5     1.82648         0.60714         NaN                        NaN\n",
       "..    ...         ...             ...         ...                        ...\n",
       "197   198     0.56186         0.75676         NaN                        NaN\n",
       "198   199     0.51107         0.80645         NaN                        NaN\n",
       "199   200     0.43155         0.80000         NaN                        NaN\n",
       "200   201     0.61842         0.80952         NaN                        NaN\n",
       "201   202     0.66698         0.82609         NaN                        NaN\n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "#once training is finished, you can retrieve the file in \"result_files=[]\"\n",
    "result_file = \"file-vJCY7Ft7qA2WlYXUSXZwZgdt\"\n",
    "\n",
    "file_data = client.files.content(result_file)\n",
    "\n",
    "# its binary, so read it and then make it a file like object\n",
    "file_data_bytes = file_data.read()\n",
    "file_like_object = io.BytesIO(file_data_bytes)\n",
    "\n",
    "#now read as csv to create df\n",
    "df = pd.read_csv(file_like_object)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a287e95",
   "metadata": {},
   "source": [
    "### Use a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97720df2-1ebc-4d58-91b0-1f68cb391eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, we do not have detailed information on Kesha's Boutique's return policy. It is recommended to visit their website or contact them directly for more information on their return policy.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries.\",\n",
    "    \"role\": \"user\", \"content\": \"What is the return policy at Kesha's Boutique?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828defbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We apologize for any confusion, but there is no specific information available about Kesha's Boutique as it could be a fictional entity. Return policies can vary by retailer, so it is best to check directly with their customer service or consult their website for detailed information on their return policy.\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = \"ft:gpt-3.5-turbo-0613:keysoft::8wX1foz7\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries for Kesha's Boutique.\",\n",
    "     \"role\": \"user\", \"content\": \"What is the return policy at Kesha's Boutique?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a901f3da-186f-4a60-8bc3-1913b0565c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is unclear whether Kesha's Boutique offers international shipping as this information is not readily available on their website or publicly stated. It is recommended to contact the boutique directly to inquire about their international shipping policies.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries.\",\n",
    "    \"role\": \"user\", \"content\": \"Does Kesha's Boutique offer international shipping?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c734a22e-9b80-45ad-a041-6ccbb2a61432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I couldn't find any information regarding Kesha's Boutique offering international shipping. It's recommended to check their website or contact their customer service for the most accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries for Kesha's Boutique.\",\n",
    "    \"role\": \"user\", \"content\": \"Does Kesha's Boutique offer international shipping?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15279a-7a4c-48ea-b270-c511bd77eb18",
   "metadata": {},
   "source": [
    "### Customer Support Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4be0b63f-18ee-4f57-8d40-0be2facb03fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  Hello! How can I assist you today? \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  I need help with shipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  Sure, I can help you with that. What specifically would you like to know about shipping? \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Do you offer international shipping?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  Yes, we offer international shipping. Shipping rates and delivery times may vary depending on the destination. You can find more information on our Shipping page. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What's the return policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  You can find our return policy on our Returns page. We offer a 30-day return window for most items, with some exceptions. If you have any specific questions about returns, please let me know. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Can I receive a discount as a first-time customer?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  We currently offer a 10% discount for first-time customers. You can find the discount code on our website or subscribe to our newsletter to receive it directly via email. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Do you accept American Express?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  Yes, we accept American Express, as well as several other major credit cards. You can find a full list of accepted payment methods in the Payment Options section during the checkout process. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Goodbye\n"
     ]
    }
   ],
   "source": [
    "#sets the persona for the AI assistant using a system message\n",
    "context = [{'role':'system', 'content': \"\"\"This is a customer support chatbot designed to help with common \n",
    "                                           inquiries for Kesha's Boutique.\"\"\"}]  \n",
    "\n",
    "def collect_messages(role, message): #keeps track of the message exchange between user and assistant\n",
    "    context.append({'role': role, 'content':f\"{message}\"})\n",
    "\n",
    "def get_completion(): \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=fine_tuned_model,\n",
    "            messages=context\n",
    "        )\n",
    "\n",
    "        print(\"\\n Assistant: \", response.choices[0].message.content, \"\\n\")\n",
    "        return response.choices[0].message.content\n",
    "    except openai.APIError as e:\n",
    "        print(e.http_status)\n",
    "        print(e.error)\n",
    "        return e.error \n",
    "\n",
    "#Start the conversation between the user and the AI assistant/chatbot\n",
    "while True:\n",
    "    collect_messages('assistant', get_completion()) #stores the response from the AI assistant\n",
    "        \n",
    "    user_prompt = input('User: ') #input box for entering prompt\n",
    "        \n",
    "    if user_prompt == 'exit': #end the conversation with the AI assistant\n",
    "        print(\"\\n Goodbye\")\n",
    "        break\n",
    "    \n",
    "    collect_messages('user', user_prompt) #stores the user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a83d6-be55-4960-8f28-4553fa8069d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
