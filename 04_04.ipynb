{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa8cd98",
   "metadata": {},
   "source": [
    "# 04_04_Retrieve and use a fine-tuned model\n",
    "# Customer Support Automation\n",
    "## Automating responses to customer inquiries on various platforms (email, chatbots, social media).\n",
    "### Collect a dataset of customer inquiries and manually crafted responses. This dataset should cover a wide range of common questions, complaints, and feedback, along with the company's standard responses. Ensure to anonymize personal information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606f61f",
   "metadata": {},
   "source": [
    "## Full Project Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126d991",
   "metadata": {},
   "source": [
    "### Install the necesarry libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc699e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai[datalib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1615b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install urllib3==1.26.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26816d3-cef3-4c39-a901-cd7a49d3fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48e61b",
   "metadata": {},
   "source": [
    "### Import the libraries and enviornment file to gain access to the Open API Key\n",
    "#### The key can be generated here: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70841de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5387008",
   "metadata": {},
   "source": [
    "### Authenticate to the API using the API Key\n",
    "#### Pull from environment variables or use openai.api_key = (\"your_key_here\") to hardcode the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf566e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY']  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e9e854-9d65-46b9-b08d-7112da95889f",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a93f9b-ca7e-4a2b-9247-03d2145f1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "#input_file=formatted_custom_support.json ; output_file=output.jsonl\n",
    "def json_to_jsonl(input_file, output_file):\n",
    "    \n",
    "    # Open JSON file\n",
    "    f = open(input_file)\n",
    "     \n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "    \n",
    "    # produce JSONL from JSON\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "def check_file_format(dataset):\n",
    "    # Format error checks\n",
    "    format_errors = defaultdict(int)\n",
    "    \n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "            \n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "            \n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "            \n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "                \n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            \n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "        \n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "    \n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No errors found\")\n",
    "\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5568135-24bf-4c5d-83ee-47e20d15113f",
   "metadata": {},
   "source": [
    "### Convert JSON to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78fa9d7-908a-42eb-81eb-69d10d65b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_jsonl('custom_support.json', 'output.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05754c20-deb7-4e3f-8e57-e9907dd6f132",
   "metadata": {},
   "source": [
    "### Check File Format\n",
    "\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16904d3c-0b0f-457b-a3ad-0fcb908f5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 101\n",
      "First example:\n",
      "{'role': 'system', 'content': \"This is a customer support chatbot designed to help with common inquiries for Kesha's Boutique.\"}\n",
      "{'role': 'user', 'content': 'How can I reset my password?'}\n",
      "{'role': 'assistant', 'content': \"You can reset your password by clicking on the 'Forgot Password' link on the login page and following the instructions sent to your email.\"}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"output.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a89f4e-b528-4b4e-b687-8458777224af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format validation\n",
    "check_file_format(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9836ae0-1c33-4ba0-8a88-03fda5ea0c5a",
   "metadata": {},
   "source": [
    "### Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3dc2da-9a08-4fbc-96a7-28ab292e513b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~7049 tokens that will be charged for during training\n",
      "By default, you'll train for 5 epochs on this dataset\n",
      "By default, you'll be charged for ~35245 tokens\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the conversation\n",
    "conversation_length = []\n",
    "\n",
    "for msg in dataset:\n",
    "    messages = msg[\"messages\"]\n",
    "    conversation_length.append(num_tokens_from_messages(messages))\n",
    "    \n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "TARGET_EPOCHS = 5\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in conversation_length)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "\n",
    "num_tokens = n_epochs * n_billing_tokens_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c234a-e9e0-40ee-a7f7-5e03bb768b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28196\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5-turbo\t$0.0080 / 1K tokens\n",
    "cost = (num_tokens/1000) * 0.0080 \n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd157b0f-dfaa-42a9-a4e5-11ba884efaf3",
   "metadata": {},
   "source": [
    "### Upload File \n",
    "#### Once you have the data validated, the file needs to be uploaded using the \n",
    "#### Files API in order to be used with a fine-tuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c62c42-90a2-480e-b55d-8c58f26dfa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-IntFuYDWVfJwMp6TpSrJa8aq', bytes=39681, created_at=1707178177, filename='output.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"output.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd054dc",
   "metadata": {},
   "source": [
    "### Create fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21da05e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ts4hC5Qakf2XzytcGrTW0GRZ', created_at=1707178194, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-RZLvEijW4GW0KmC3rLIAjZlu', result_files=[], status='validating_files', trained_tokens=None, training_file='file-IntFuYDWVfJwMp6TpSrJa8aq', validation_file=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the fine-tuning job \n",
    "# After you've started a fine-tuning job, it may take some time to complete. Your job may be queued \n",
    "# behind other jobs and training a model can take minutes or hours depending on the \n",
    "# model and dataset size. \n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-IntFuYDWVfJwMp6TpSrJa8aq\", \n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":5\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ebec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ts4hC5Qakf2XzytcGrTW0GRZ', created_at=1707178194, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:keysoft::8p3gc9SA', finished_at=1707179589, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-RZLvEijW4GW0KmC3rLIAjZlu', result_files=['file-4XHPig2LQ1VAUTnVIPqlbWJO'], status='succeeded', trained_tokens=34235, training_file='file-IntFuYDWVfJwMp6TpSrJa8aq', validation_file=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve job status\n",
    "job_id = \"ftjob-ts4hC5Qakf2XzytcGrTW0GRZ\"\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "# Status field can contain: running or succeeded or failed, etc.\n",
    "client.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd98e42-8dac-438b-a622-4f361d0434f1",
   "metadata": {},
   "source": [
    "### Evaluate results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd35ca4d-3a41-42d8-baad-1ee0e219158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_mean_token_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.62449</td>\n",
       "      <td>0.74194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.58815</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.68213</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.31334</td>\n",
       "      <td>0.60870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.89790</td>\n",
       "      <td>0.61290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>501</td>\n",
       "      <td>0.16619</td>\n",
       "      <td>0.92593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>502</td>\n",
       "      <td>0.49473</td>\n",
       "      <td>0.79412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>503</td>\n",
       "      <td>0.24529</td>\n",
       "      <td>0.90909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>504</td>\n",
       "      <td>0.28140</td>\n",
       "      <td>0.89286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>505</td>\n",
       "      <td>0.45056</td>\n",
       "      <td>0.84848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
       "0       1     1.62449         0.74194         NaN                        NaN\n",
       "1       2     1.58815         0.62963         NaN                        NaN\n",
       "2       3     1.68213         0.60000         NaN                        NaN\n",
       "3       4     2.31334         0.60870         NaN                        NaN\n",
       "4       5     1.89790         0.61290         NaN                        NaN\n",
       "..    ...         ...             ...         ...                        ...\n",
       "500   501     0.16619         0.92593         NaN                        NaN\n",
       "501   502     0.49473         0.79412         NaN                        NaN\n",
       "502   503     0.24529         0.90909         NaN                        NaN\n",
       "503   504     0.28140         0.89286         NaN                        NaN\n",
       "504   505     0.45056         0.84848         NaN                        NaN\n",
       "\n",
       "[505 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "#once training is finished, you can retrieve the file in \"result_files=[]\"\n",
    "result_file = \"file-4XHPig2LQ1VAUTnVIPqlbWJO\"\n",
    "\n",
    "file_data = client.files.content(result_file)\n",
    "\n",
    "# its binary, so read it and then make it a file like object\n",
    "file_data_bytes = file_data.read()\n",
    "file_like_object = io.BytesIO(file_data_bytes)\n",
    "\n",
    "#now read as csv to create df\n",
    "df = pd.read_csv(file_like_object)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a287e95",
   "metadata": {},
   "source": [
    "### Use a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97720df2-1ebc-4d58-91b0-1f68cb391eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but as an AI language model, I do not have access to specific information about the return policy at Kesha's Boutique. To find out about their return policy, I recommend visiting their official website or contacting their customer service directly.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries.\",\n",
    "    \"role\": \"user\", \"content\": \"What is the return policy at Kesha's Boutique?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "828defbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our return policy allows customers to return items within 30 days of purchase for a full refund, as long as the items are in their original condition. Sale items and certain products may have different return conditions, so please check our return policy page for more details.\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = \"ft:gpt-3.5-turbo-0613:keysoft::8p2M8Tzi\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries for Kesha's Boutique.\",\n",
    "     \"role\": \"user\", \"content\": \"What is the return policy at Kesha's Boutique?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a901f3da-186f-4a60-8bc3-1913b0565c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but as an AI language model, I do not have access to current information about the operations of specific businesses. To determine whether Kesha's Boutique offers international shipping, I recommend visiting their official website or contacting their customer service for the most accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries.\",\n",
    "    \"role\": \"user\", \"content\": \"Does Kesha's Boutique offer international shipping?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c734a22e-9b80-45ad-a041-6ccbb2a61432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Kesha's Boutique offers international shipping to select countries. You can check their shipping policies on their website or contact customer service for more information.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a customer support chatbot designed to help with common inquiries for Kesha's Boutique.\",\n",
    "    \"role\": \"user\", \"content\": \"Does Kesha's Boutique offer international shipping?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
